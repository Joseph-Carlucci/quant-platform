[2025-06-22T18:33:01.545+0000] {processor.py:161} INFO - Started process (PID=198) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:33:01.545+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:33:01.546+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:33:01.546+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:33:01.991+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:33:02.108+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:33:02.107+0000] {override.py:1617} ERROR - Add Permission: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(sample_data_pipeline) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'sample_data_pipeline', 'fileloc': '/opt/airflow/dags/sample_data_pipeline.py', 'fileloc_hash': 29124124989473270, 'data': '{"__version": 1, "dag": {"schedule_interval": {"__var": 3600.0, "__type": "timedelta"}, "dataset_triggers": [], "timezone": "UTC", "catchup": false,  ... (2930 characters truncated) ... onOperator", "_task_module": "airflow.operators.python", "_is_empty": false, "op_args": [], "op_kwargs": {}}], "dag_dependencies": [], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 6, 22, 18, 33, 2, 6215, tzinfo=Timezone('UTC')), 'dag_hash': 'e6a274163069abc488b6e2733878b4b3', 'processor_subdir': '/opt/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
[2025-06-22T18:33:02.110+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:33:02.110+0000] {override.py:1772} ERROR - Creation of Permission View Error: (psycopg2.errors.ForeignKeyViolation) insert or update on table "ab_permission_view" violates foreign key constraint "ab_permission_view_permission_id_fkey"
DETAIL:  Key (permission_id)=(2) is not present in table "ab_permission".

[SQL: INSERT INTO ab_permission_view (permission_id, view_menu_id) VALUES (%(permission_id)s, %(view_menu_id)s) RETURNING ab_permission_view.id]
[parameters: {'permission_id': 2, 'view_menu_id': 1}]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
[2025-06-22T18:33:02.115+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:33:02.114+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:33:02.121+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:33:02.120+0000] {dag.py:3055} INFO - Creating ORM DAG for sample_data_pipeline
[2025-06-22T18:33:02.126+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:33:02.126+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T17:00:00+00:00, run_after=2025-06-22T18:00:00+00:00
[2025-06-22T18:33:02.419+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:33:02.418+0000] {dagbag.py:647} ERROR - Failed to write serialized DAG: /opt/airflow/dags/sample_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dag_pkey"
DETAIL:  Key (dag_id)=(sample_data_pipeline) already exists.

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: {'dag_id': 'sample_data_pipeline', 'root_dag_id': None, 'is_paused': False, 'is_subdag': False, 'is_active': True, 'last_parsed_time': datetime.datetime(2025, 6, 22, 18, 33, 2, 126512, tzinfo=Timezone('UTC')), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/sample_data_pipeline.py', 'processor_subdir': '/opt/airflow/dags', 'owners': 'quant-team', 'description': 'Sample data ingestion pipeline for quant research', 'default_view': 'grid', 'schedule_interval': '{"type": "timedelta", "attrs": {"days": 0, "seconds": 3600, "microseconds": 0}}', 'timetable_description': '', 'max_active_tasks': 16, 'max_active_runs': 16, 'has_task_concurrency_limits': False, 'has_import_errors': False, 'next_dagrun': DateTime(2025, 6, 22, 17, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_data_interval_start': DateTime(2025, 6, 22, 17, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_data_interval_end': DateTime(2025, 6, 22, 18, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_create_after': DateTime(2025, 6, 22, 18, 0, 0, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-06-22T18:33:02.420+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:33:02.420+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:33:02.420+0000] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 895, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.11/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/tenacity/__init__.py", line 314, in iter
    return fut.result()
           ^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dagbag.py", line 673, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/airflow/models/dag.py", line 3045, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dag_pkey"
DETAIL:  Key (dag_id)=(sample_data_pipeline) already exists.

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: {'dag_id': 'sample_data_pipeline', 'root_dag_id': None, 'is_paused': False, 'is_subdag': False, 'is_active': True, 'last_parsed_time': datetime.datetime(2025, 6, 22, 18, 33, 2, 126512, tzinfo=Timezone('UTC')), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/sample_data_pipeline.py', 'processor_subdir': '/opt/airflow/dags', 'owners': 'quant-team', 'description': 'Sample data ingestion pipeline for quant research', 'default_view': 'grid', 'schedule_interval': '{"type": "timedelta", "attrs": {"days": 0, "seconds": 3600, "microseconds": 0}}', 'timetable_description': '', 'max_active_tasks': 16, 'max_active_runs': 16, 'has_task_concurrency_limits': False, 'has_import_errors': False, 'next_dagrun': DateTime(2025, 6, 22, 17, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_data_interval_start': DateTime(2025, 6, 22, 17, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_data_interval_end': DateTime(2025, 6, 22, 18, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_create_after': DateTime(2025, 6, 22, 18, 0, 0, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-06-22T18:33:32.620+0000] {processor.py:161} INFO - Started process (PID=254) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:33:32.620+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:33:32.620+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:33:32.620+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:33:32.737+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:33:32.779+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:33:32.779+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:33:32.787+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:33:32.787+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:33:32.795+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.177 seconds
[2025-06-22T18:34:02.934+0000] {processor.py:161} INFO - Started process (PID=263) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:34:02.935+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:34:02.936+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:34:02.936+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:34:03.067+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:34:03.085+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:34:03.085+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:34:03.098+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:34:03.097+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:34:03.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.177 seconds
[2025-06-22T18:34:33.378+0000] {processor.py:161} INFO - Started process (PID=275) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:34:33.382+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:34:33.383+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:34:33.383+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:34:33.535+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:34:33.556+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:34:33.556+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:34:33.567+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:34:33.567+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:34:33.580+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.204 seconds
[2025-06-22T18:35:03.744+0000] {processor.py:161} INFO - Started process (PID=288) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:35:03.744+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:35:03.746+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:35:03.746+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:35:03.886+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:35:03.907+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:35:03.907+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:35:03.918+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:35:03.918+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:35:03.930+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.188 seconds
[2025-06-22T18:35:34.266+0000] {processor.py:161} INFO - Started process (PID=300) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:35:34.266+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:35:34.267+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:35:34.267+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:35:34.401+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:35:34.419+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:35:34.419+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:35:34.431+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:35:34.430+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:35:34.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.178 seconds
[2025-06-22T18:36:04.580+0000] {processor.py:161} INFO - Started process (PID=312) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:36:04.581+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:36:04.583+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:36:04.583+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:36:04.721+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:36:04.740+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:36:04.740+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:36:04.750+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:36:04.750+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:36:04.761+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.183 seconds
[2025-06-22T18:36:35.117+0000] {processor.py:161} INFO - Started process (PID=324) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:36:35.117+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:36:35.118+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:36:35.118+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:36:35.246+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:36:35.261+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:36:35.260+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:36:35.271+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:36:35.271+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:36:35.285+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.169 seconds
[2025-06-22T18:37:05.423+0000] {processor.py:161} INFO - Started process (PID=336) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:37:05.423+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:37:05.424+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:37:05.424+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:37:05.559+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:37:05.582+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:37:05.582+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:37:05.591+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:37:05.591+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:37:05.602+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.183 seconds
[2025-06-22T18:37:35.910+0000] {processor.py:161} INFO - Started process (PID=348) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:37:35.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:37:35.912+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:37:35.912+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:37:36.044+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:37:36.058+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:37:36.057+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:37:36.070+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:37:36.070+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:37:36.083+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.175 seconds
[2025-06-22T18:38:06.428+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:38:06.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:38:06.429+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:38:06.429+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:38:06.560+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:38:06.577+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:38:06.577+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:38:06.589+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:38:06.589+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:38:06.601+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.174 seconds
[2025-06-22T18:38:36.853+0000] {processor.py:161} INFO - Started process (PID=375) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:38:36.854+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:38:36.854+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:38:36.854+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:38:36.986+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:38:37.003+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:38:37.003+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:38:37.016+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:38:37.016+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:38:37.028+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.176 seconds
[2025-06-22T18:39:07.182+0000] {processor.py:161} INFO - Started process (PID=387) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:39:07.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:39:07.185+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:39:07.185+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:39:07.327+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:39:07.343+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:39:07.343+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:39:07.355+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:39:07.355+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:39:07.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.187 seconds
[2025-06-22T18:39:37.695+0000] {processor.py:161} INFO - Started process (PID=399) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:39:37.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:39:37.703+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:39:37.703+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:39:37.827+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:39:37.841+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:39:37.840+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:39:37.852+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:39:37.852+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:39:37.866+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.173 seconds
[2025-06-22T18:40:08.215+0000] {processor.py:161} INFO - Started process (PID=427) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:40:08.215+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:40:08.216+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:40:08.216+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:40:08.359+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:40:08.375+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:40:08.375+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:40:08.388+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:40:08.388+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:40:08.398+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.185 seconds
[2025-06-22T18:40:38.546+0000] {processor.py:161} INFO - Started process (PID=455) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:40:38.547+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:40:38.547+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:40:38.547+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:40:38.679+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:40:38.694+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:40:38.694+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:40:38.704+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:40:38.704+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:40:38.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.171 seconds
[2025-06-22T18:41:09.080+0000] {processor.py:161} INFO - Started process (PID=479) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:41:09.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:41:09.082+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:41:09.081+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:41:09.215+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:41:09.234+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:41:09.233+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:41:09.243+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:41:09.243+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:41:09.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.175 seconds
[2025-06-22T18:41:39.640+0000] {processor.py:161} INFO - Started process (PID=491) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:41:39.647+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:41:39.651+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:41:39.651+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:41:39.787+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:41:39.802+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:41:39.802+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:41:39.814+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:41:39.813+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:41:39.826+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.188 seconds
[2025-06-22T18:42:09.993+0000] {processor.py:161} INFO - Started process (PID=519) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:42:09.994+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:42:09.994+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:42:09.994+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:42:10.131+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:42:10.147+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:42:10.146+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:42:10.160+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:42:10.160+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:42:10.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.180 seconds
[2025-06-22T18:42:40.526+0000] {processor.py:161} INFO - Started process (PID=534) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:42:40.528+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:42:40.529+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:42:40.528+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:42:40.678+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:42:40.694+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:42:40.693+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:42:40.704+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:42:40.704+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:42:40.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.191 seconds
[2025-06-22T18:43:11.062+0000] {processor.py:161} INFO - Started process (PID=546) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:43:11.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:43:11.065+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:43:11.064+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:43:11.210+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:43:11.223+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:43:11.223+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:43:11.233+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:43:11.233+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:43:11.242+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.185 seconds
[2025-06-22T18:43:41.579+0000] {processor.py:161} INFO - Started process (PID=558) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:43:41.580+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:43:41.581+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:43:41.580+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:43:41.719+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:43:41.734+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:43:41.733+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:43:41.744+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:43:41.744+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:43:41.754+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.177 seconds
[2025-06-22T18:44:12.099+0000] {processor.py:161} INFO - Started process (PID=570) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:44:12.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:44:12.101+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:44:12.101+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:44:12.237+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:44:12.251+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:44:12.251+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:44:12.260+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:44:12.260+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:44:12.269+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.174 seconds
[2025-06-22T18:44:42.661+0000] {processor.py:161} INFO - Started process (PID=582) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:44:42.662+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:44:42.663+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:44:42.662+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:44:42.791+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:44:42.803+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:44:42.803+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:44:42.813+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:44:42.813+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:44:42.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.163 seconds
[2025-06-22T18:45:13.232+0000] {processor.py:161} INFO - Started process (PID=600) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:45:13.233+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:45:13.234+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:45:13.234+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:45:13.384+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:45:13.398+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:45:13.398+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:45:13.408+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:45:13.407+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:45:13.418+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.190 seconds
[2025-06-22T18:45:43.691+0000] {processor.py:161} INFO - Started process (PID=612) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:45:43.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:45:43.693+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:45:43.692+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:45:43.840+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:45:43.853+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:45:43.853+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:45:43.862+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:45:43.862+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:45:43.871+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.185 seconds
[2025-06-22T18:46:26.808+0000] {processor.py:161} INFO - Started process (PID=228) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:46:26.811+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:46:26.811+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:46:26.811+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:46:27.218+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:46:27.241+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:46:27.241+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:46:27.252+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:46:27.252+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:46:27.261+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.455 seconds
[2025-06-22T18:46:57.553+0000] {processor.py:161} INFO - Started process (PID=294) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:46:57.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:46:57.555+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:46:57.555+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:46:57.684+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:46:57.728+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:46:57.728+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:46:57.736+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:46:57.736+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:46:57.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.198 seconds
[2025-06-22T18:47:27.839+0000] {processor.py:161} INFO - Started process (PID=306) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:47:27.839+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:47:27.840+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:47:27.840+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:47:27.973+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:47:27.988+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:47:27.988+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:47:27.998+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:47:27.998+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:47:28.009+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.174 seconds
[2025-06-22T18:47:58.402+0000] {processor.py:161} INFO - Started process (PID=318) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:47:58.403+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:47:58.403+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:47:58.403+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:47:58.530+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:47:58.545+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:47:58.544+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:47:58.557+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:47:58.557+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:47:58.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.167 seconds
[2025-06-22T18:48:28.869+0000] {processor.py:161} INFO - Started process (PID=330) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:48:28.870+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:48:28.871+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:48:28.870+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:48:29.001+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:48:29.015+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:48:29.015+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:48:29.025+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:48:29.025+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:48:29.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.170 seconds
[2025-06-22T18:48:59.168+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:48:59.169+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:48:59.170+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:48:59.170+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:48:59.319+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:48:59.338+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:48:59.337+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:48:59.348+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:48:59.348+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:48:59.361+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.196 seconds
[2025-06-22T18:49:29.564+0000] {processor.py:161} INFO - Started process (PID=354) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:49:29.565+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:49:29.565+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:49:29.565+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:49:29.699+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:49:29.715+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:49:29.715+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:49:29.727+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:49:29.727+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:49:29.738+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.176 seconds
[2025-06-22T18:50:00.113+0000] {processor.py:161} INFO - Started process (PID=366) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:50:00.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:50:00.115+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:50:00.114+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:50:00.258+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:50:00.272+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:50:00.272+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:50:00.283+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:50:00.283+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:50:00.296+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.186 seconds
[2025-06-22T18:50:30.484+0000] {processor.py:161} INFO - Started process (PID=378) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:50:30.484+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:50:30.485+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:50:30.485+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:50:30.614+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:50:30.630+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:50:30.630+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:50:30.642+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:50:30.642+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:50:30.655+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.174 seconds
[2025-06-22T18:51:00.970+0000] {processor.py:161} INFO - Started process (PID=390) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:51:00.971+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:51:00.972+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:51:00.972+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:51:01.112+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:51:01.131+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:51:01.131+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:51:01.142+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:51:01.141+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:51:01.154+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.187 seconds
[2025-06-22T18:51:31.516+0000] {processor.py:161} INFO - Started process (PID=411) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:51:31.517+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:51:31.518+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:51:31.518+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:51:31.654+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:51:31.668+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:51:31.668+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:51:31.681+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:51:31.681+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:51:31.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.181 seconds
[2025-06-22T18:52:01.972+0000] {processor.py:161} INFO - Started process (PID=423) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:52:01.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:52:01.973+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:52:01.973+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:52:02.102+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:52:02.118+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:52:02.118+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:52:02.129+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:52:02.128+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:52:02.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.169 seconds
[2025-06-22T18:52:32.249+0000] {processor.py:161} INFO - Started process (PID=435) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:52:32.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:52:32.250+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:52:32.250+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:52:32.386+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:52:32.402+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:52:32.401+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:52:32.411+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:52:32.411+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:52:32.422+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.176 seconds
[2025-06-22T18:53:02.797+0000] {processor.py:161} INFO - Started process (PID=447) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:53:02.799+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:53:02.800+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:53:02.800+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:53:02.934+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:53:02.950+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:53:02.950+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:53:02.963+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:53:02.963+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:53:02.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.181 seconds
[2025-06-22T18:53:33.326+0000] {processor.py:161} INFO - Started process (PID=480) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:53:33.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:53:33.328+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:53:33.328+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:53:33.462+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:53:33.475+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:53:33.475+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:53:33.484+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:53:33.484+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:53:33.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.171 seconds
[2025-06-22T18:54:03.827+0000] {processor.py:161} INFO - Started process (PID=517) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:54:03.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:54:03.828+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:54:03.828+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:54:03.952+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:54:03.967+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:54:03.967+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:54:03.978+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:54:03.978+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:54:03.988+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.163 seconds
[2025-06-22T18:54:34.455+0000] {processor.py:161} INFO - Started process (PID=580) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:54:34.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:54:34.457+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:54:34.457+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:54:34.595+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:54:34.608+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:54:34.608+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:54:34.619+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:54:34.619+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:54:34.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.177 seconds
[2025-06-22T18:55:04.977+0000] {processor.py:161} INFO - Started process (PID=592) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:55:04.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:55:04.979+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:55:04.978+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:55:05.106+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:55:05.120+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:55:05.119+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:55:05.129+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:55:05.129+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:55:05.137+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.164 seconds
[2025-06-22T18:55:35.484+0000] {processor.py:161} INFO - Started process (PID=604) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:55:35.484+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:55:35.485+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:55:35.485+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:55:35.616+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:55:35.629+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:55:35.628+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:55:35.638+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:55:35.638+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:55:35.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.166 seconds
[2025-06-22T18:56:05.982+0000] {processor.py:161} INFO - Started process (PID=629) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:56:05.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:56:05.984+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:56:05.984+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:56:06.127+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:56:06.140+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:56:06.139+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:56:06.149+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:56:06.149+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:56:06.156+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.178 seconds
[2025-06-22T18:56:36.470+0000] {processor.py:161} INFO - Started process (PID=641) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:56:36.470+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:56:36.471+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:56:36.471+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:56:36.600+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:56:36.614+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:56:36.614+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:56:36.624+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:56:36.624+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:56:36.633+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.165 seconds
[2025-06-22T18:57:06.961+0000] {processor.py:161} INFO - Started process (PID=669) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:57:06.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:57:06.963+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:57:06.962+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:57:07.116+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:57:07.130+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:57:07.129+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:57:07.140+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:57:07.140+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:57:07.149+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.193 seconds
[2025-06-22T18:57:37.513+0000] {processor.py:161} INFO - Started process (PID=681) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:57:37.514+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:57:37.515+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:57:37.515+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:57:37.653+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:57:37.668+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:57:37.667+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:57:37.679+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:57:37.679+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:57:37.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.178 seconds
[2025-06-22T18:58:08.032+0000] {processor.py:161} INFO - Started process (PID=693) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:58:08.033+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:58:08.034+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:58:08.033+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:58:08.176+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:58:08.192+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:58:08.192+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:58:08.204+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:58:08.204+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:58:08.213+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.186 seconds
[2025-06-22T18:58:38.484+0000] {processor.py:161} INFO - Started process (PID=733) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:58:38.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:58:38.485+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:58:38.485+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:58:38.619+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:58:38.633+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:58:38.633+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:58:38.642+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:58:38.642+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:58:38.653+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.170 seconds
[2025-06-22T18:59:09.148+0000] {processor.py:161} INFO - Started process (PID=789) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:59:09.149+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:59:09.150+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:59:09.150+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:59:09.282+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:59:09.295+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:59:09.295+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:59:09.303+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:59:09.303+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:59:09.311+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.166 seconds
[2025-06-22T18:59:39.584+0000] {processor.py:161} INFO - Started process (PID=813) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:59:39.584+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T18:59:39.585+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:59:39.584+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:59:39.703+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T18:59:39.716+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:59:39.716+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T18:59:39.725+0000] {logging_mixin.py:188} INFO - [2025-06-22T18:59:39.725+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T18:00:00+00:00, run_after=2025-06-22T19:00:00+00:00
[2025-06-22T18:59:39.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.151 seconds
[2025-06-22T19:00:10.044+0000] {processor.py:161} INFO - Started process (PID=834) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:00:10.045+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:00:10.046+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:00:10.045+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:00:10.176+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:00:10.189+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:00:10.189+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:00:10.198+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:00:10.198+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:00:10.205+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.166 seconds
[2025-06-22T19:00:40.488+0000] {processor.py:161} INFO - Started process (PID=846) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:00:40.488+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:00:40.489+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:00:40.488+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:00:40.621+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:00:40.634+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:00:40.634+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:00:40.644+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:00:40.643+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:00:40.650+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.165 seconds
[2025-06-22T19:01:10.907+0000] {processor.py:161} INFO - Started process (PID=861) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:01:10.908+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:01:10.909+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:01:10.908+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:01:11.037+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:01:11.050+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:01:11.050+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:01:11.059+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:01:11.059+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:01:11.067+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.163 seconds
[2025-06-22T19:01:41.395+0000] {processor.py:161} INFO - Started process (PID=873) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:01:41.396+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:01:41.397+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:01:41.396+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:01:41.529+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:01:41.542+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:01:41.542+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:01:41.553+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:01:41.553+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:01:41.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.169 seconds
[2025-06-22T19:02:11.875+0000] {processor.py:161} INFO - Started process (PID=885) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:02:11.876+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:02:11.877+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:02:11.877+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:02:12.006+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:02:12.018+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:02:12.018+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:02:12.027+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:02:12.027+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:02:12.035+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.163 seconds
[2025-06-22T19:02:42.415+0000] {processor.py:161} INFO - Started process (PID=897) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:02:42.416+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:02:42.417+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:02:42.417+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:02:42.542+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:02:42.555+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:02:42.554+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:02:42.564+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:02:42.564+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:02:42.572+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.161 seconds
[2025-06-22T19:03:12.902+0000] {processor.py:161} INFO - Started process (PID=909) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:03:12.903+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:03:12.904+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:03:12.904+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:03:13.049+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:03:13.063+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:03:13.062+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:03:13.075+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:03:13.075+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:03:13.083+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.187 seconds
[2025-06-22T19:03:43.517+0000] {processor.py:161} INFO - Started process (PID=921) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:03:43.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:03:43.519+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:03:43.519+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:03:43.661+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:03:43.676+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:03:43.676+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:03:43.686+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:03:43.686+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:03:43.696+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.182 seconds
[2025-06-22T19:11:57.219+0000] {processor.py:161} INFO - Started process (PID=930) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:11:57.219+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:11:57.221+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:11:57.221+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:11:57.361+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:11:57.375+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:11:57.375+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:11:57.387+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:11:57.387+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:11:57.398+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.183 seconds
[2025-06-22T19:12:27.810+0000] {processor.py:161} INFO - Started process (PID=948) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:12:27.811+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:12:27.812+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:12:27.812+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:12:27.954+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:12:27.971+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:12:27.971+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:12:27.985+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:12:27.985+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:12:27.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.188 seconds
[2025-06-22T19:12:58.163+0000] {processor.py:161} INFO - Started process (PID=960) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:12:58.165+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:12:58.168+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:12:58.167+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:12:58.308+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:12:58.323+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:12:58.323+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:12:58.334+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:12:58.334+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:12:58.347+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.187 seconds
[2025-06-22T19:13:28.658+0000] {processor.py:161} INFO - Started process (PID=972) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:13:28.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:13:28.660+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:13:28.660+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:13:28.793+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:13:28.806+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:13:28.806+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:13:28.816+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:13:28.816+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:13:28.827+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.171 seconds
[2025-06-22T19:13:58.967+0000] {processor.py:161} INFO - Started process (PID=984) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:13:58.969+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:13:58.972+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:13:58.972+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:13:59.097+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:13:59.113+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:13:59.112+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:13:59.126+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:13:59.126+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:13:59.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.176 seconds
[2025-06-22T19:14:29.502+0000] {processor.py:161} INFO - Started process (PID=996) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:14:29.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:14:29.504+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:14:29.504+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:14:29.634+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:14:29.648+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:14:29.648+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:14:29.657+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:14:29.657+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:14:29.668+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.168 seconds
[2025-06-22T19:15:00.025+0000] {processor.py:161} INFO - Started process (PID=1008) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:15:00.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:15:00.032+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:15:00.032+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:15:00.161+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:15:00.173+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:15:00.173+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:15:00.183+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:15:00.183+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:15:00.194+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.171 seconds
[2025-06-22T19:15:30.543+0000] {processor.py:161} INFO - Started process (PID=1020) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:15:30.544+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:15:30.544+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:15:30.544+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:15:30.674+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:15:30.690+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:15:30.690+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:15:30.700+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:15:30.700+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:15:30.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.171 seconds
[2025-06-22T19:16:00.797+0000] {processor.py:161} INFO - Started process (PID=1032) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:16:00.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:16:00.798+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:16:00.798+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:16:00.924+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:16:00.939+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:16:00.939+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:16:00.950+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:16:00.950+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:16:00.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.165 seconds
[2025-06-22T19:16:31.095+0000] {processor.py:161} INFO - Started process (PID=1044) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:16:31.098+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:16:31.102+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:16:31.102+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:16:31.230+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:16:31.244+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:16:31.243+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:16:31.253+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:16:31.253+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:16:31.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.171 seconds
[2025-06-22T19:17:01.555+0000] {processor.py:161} INFO - Started process (PID=1056) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:17:01.555+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:17:01.557+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:17:01.556+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:17:01.690+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:17:01.705+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:17:01.705+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:17:01.716+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:17:01.716+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:17:01.725+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.174 seconds
[2025-06-22T19:17:31.894+0000] {processor.py:161} INFO - Started process (PID=1068) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:17:31.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:17:31.895+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:17:31.895+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:17:32.026+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:17:32.040+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:17:32.040+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:17:32.050+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:17:32.050+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:17:32.062+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.170 seconds
[2025-06-22T19:18:02.448+0000] {processor.py:161} INFO - Started process (PID=1080) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:18:02.449+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:18:02.450+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:18:02.449+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:18:02.577+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:18:02.595+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:18:02.595+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:18:02.606+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:18:02.606+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:18:02.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.184 seconds
[2025-06-22T19:18:33.027+0000] {processor.py:161} INFO - Started process (PID=1092) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:18:33.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:18:33.028+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:18:33.028+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:18:33.161+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:18:33.176+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:18:33.176+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:18:33.186+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:18:33.186+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:18:33.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.174 seconds
[2025-06-22T19:19:03.303+0000] {processor.py:161} INFO - Started process (PID=1104) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:19:03.304+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:19:03.304+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:19:03.304+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:19:03.446+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:19:03.460+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:19:03.460+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:19:03.472+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:19:03.472+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:19:03.483+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.182 seconds
[2025-06-22T19:19:33.818+0000] {processor.py:161} INFO - Started process (PID=1116) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:19:33.819+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:19:33.820+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:19:33.820+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:19:33.957+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:19:33.971+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:19:33.971+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:19:34.072+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:19:34.072+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:19:34.083+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.267 seconds
[2025-06-22T19:20:04.146+0000] {processor.py:161} INFO - Started process (PID=1128) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:20:04.147+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:20:04.148+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:20:04.148+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:20:04.278+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:20:04.293+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:20:04.292+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:20:04.304+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:20:04.304+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:20:04.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.171 seconds
[2025-06-22T19:20:34.621+0000] {processor.py:161} INFO - Started process (PID=1140) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:20:34.622+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:20:34.622+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:20:34.622+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:20:34.767+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:20:34.786+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:20:34.785+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:20:34.795+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:20:34.795+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:20:34.891+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.272 seconds
[2025-06-22T19:21:04.930+0000] {processor.py:161} INFO - Started process (PID=1152) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:21:04.935+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:21:04.937+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:21:04.936+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:21:05.071+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:21:05.087+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:21:05.086+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:21:05.097+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:21:05.097+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:21:05.107+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.179 seconds
[2025-06-22T19:21:35.297+0000] {processor.py:161} INFO - Started process (PID=1164) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:21:35.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:21:35.298+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:21:35.298+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:21:35.428+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:21:35.443+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:21:35.442+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:21:35.452+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:21:35.451+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:21:35.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.168 seconds
[2025-06-22T19:22:05.769+0000] {processor.py:161} INFO - Started process (PID=1176) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:22:05.770+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:22:05.771+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:22:05.771+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:22:05.902+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:22:05.916+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:22:05.916+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:22:06.014+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:22:06.014+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:22:06.025+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.258 seconds
[2025-06-22T19:22:36.097+0000] {processor.py:161} INFO - Started process (PID=1188) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:22:36.098+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:22:36.100+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:22:36.100+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:22:36.239+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:22:36.345+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:22:36.344+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:22:36.355+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:22:36.355+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:22:36.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.272 seconds
[2025-06-22T19:23:06.591+0000] {processor.py:161} INFO - Started process (PID=1200) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:23:06.592+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:23:06.593+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:23:06.592+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:23:06.730+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:23:06.745+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:23:06.745+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:23:06.756+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:23:06.756+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:23:06.860+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.271 seconds
[2025-06-22T19:23:37.037+0000] {processor.py:161} INFO - Started process (PID=1212) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:23:37.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:23:37.040+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:23:37.040+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:23:37.176+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:23:37.278+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:23:37.191+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:23:37.287+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:23:37.287+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:23:37.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.263 seconds
[2025-06-22T19:24:07.485+0000] {processor.py:161} INFO - Started process (PID=1224) to work on /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:24:07.488+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/sample_data_pipeline.py for tasks to queue
[2025-06-22T19:24:07.489+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:24:07.488+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:24:07.618+0000] {processor.py:840} INFO - DAG(s) 'sample_data_pipeline' retrieved from /opt/airflow/dags/sample_data_pipeline.py
[2025-06-22T19:24:07.634+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:24:07.634+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2025-06-22T19:24:07.643+0000] {logging_mixin.py:188} INFO - [2025-06-22T19:24:07.643+0000] {dag.py:3820} INFO - Setting next_dagrun for sample_data_pipeline to 2025-06-22T19:00:00+00:00, run_after=2025-06-22T20:00:00+00:00
[2025-06-22T19:24:07.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/sample_data_pipeline.py took 0.175 seconds
